---
title: 情报推荐（3）
date: 2023-11-06 19:03:18
tags: [推荐系统, 研究生课程]
categories: [研究生课程]
mathjax: true
cover: https://s2.loli.net/2023/10/28/cTiwMuImVXsdL8E.jpg
katex: true
---

# 基于模型的协同过滤
基于模型的协同过滤（Model-Based Collaborative Filtering）是一种推荐系统技术，它使用统计模型来预测用户对项目的喜好。与传统的基于邻域的协同过滤方法（如用户-用户协同过滤和项目-项目协同过滤）不同，基于模型的协同过滤方法使用机器学习或其他数学模型来学习用户和项目之间的关系，从而进行推荐。

基于模型的协同过滤通常分为两种类型：

矩阵分解（Matrix Factorization）：矩阵分解是基于模型的协同过滤中常用的一种技术。它将用户-项目评分矩阵分解为两个低维矩阵，一个表示用户的特征，另一个表示项目的特征。通过学习这些特征向量，系统可以预测缺失的评分，从而为用户生成推荐。

深度学习方法：随着深度学习技术的发展，研究者们开始尝试使用神经网络等深度学习模型来进行基于模型的协同过滤。这些深度学习模型能够处理大规模的数据集，并且能够学习到更复杂的用户和项目之间的关系，提高了推荐系统的性能。

## 基于规则的协同过滤
### 关联规则
首先我们要介绍一个概念叫做 **“关联规则”**。
>关联规则是数据挖掘中的一种技术，用于发现在一个数据集中不同项目之间的有趣关系。这种方法最著名的应用是在市场篮分析中，它帮助零售商了解哪些产品经常一起被购买。关联规则可以表述为“如果...那么...”的形式，例如，“如果顾客购买了面包，他们也倾向于购买牛奶”。

关联规则有以下几个常用的指标来度量物品间的相关度。下面我会依次介绍。

#### 支持度
"支持度"（Support）是一个非常重要的概念。关联规则是用来发现在一个数据集中不同项目之间的有趣关系，如购物篮分析中的物品组合。在这种分析中，支持度用来量化一组项目在整个数据集中出现的频率。

更具体地说，支持度被定义为特定规则涵盖的数据集比例。如果我们用 
$A ⇒ B$ 表示一个关联规则（意味着当A发生时，B也倾向于发生），那么这个规则的支持度可以定义为：

$$
支持度 (A⇒B) =  \frac{同时包含A和B的事务数}{所有事务的总数}
$$

| 顾客   | 面包 | 黄油 | 牛奶 | 鱼 | 牛肉 | 火腿 |
| ------ | ---- | ---- | ------ | ---- | ---- | ---- |
| Jack   | 1    | 1    | 1      | 0    | 0    | 0    |
| Mary   | 0    | 1    | 1      | 0    | 1    | 0    |
| Jane   | 1    | 1    | 0      | 0    | 0    | 0    |
| Sayani | 1    | 1    | 1      | 1    | 1    | 1    |
| John   | 0    | 0    | 0      | 1    | 0    | 1    |
| Tom    | 0    | 1    | 1      | 0    | 1    | 1    |
| Peter  | 0    | 1    | 0      | 1    | 1    | 0    |

在这里我们考虑一个关联规则： **买了黄油和牛奶的人，就会买面包**。如果用数学语言我们可以将这个关联规则表示成

$$
\{黄油, 牛奶\} ⇒ \{面包\}
$$

我们来数一数，表格中有几个人是符合这个规则的，我们发现

> 同时买了黄油，牛奶的人有4个人，分别是Jack, Mary, Sayani, Tom
> 买了面包的有3个人，分别是Jack,Jane,Sayani
>
> 所以同时买了三者的人有**两个人**，是Jack和Sayani
> 总共有**8条记录**


所以这里支持度为：$2/8=25\% $

#### 置信度
光有支持度还不够，我们要看关联规则的 **“强度”** 怎么样，有了强度我们才能知道我们定义的这条规则合理不合理，例如，我们说买了黄油的人就会买面包了，听起来就很合理，但如果我们说买了黄油的人就会买火腿，听起来好像不太对……
>那我们要怎么看“强度”呢

我们用置信度来定义“关联规则的强度”，最基本的思想就是，我们看看这条规则在表格中出现了几次（百分比是多少），具体来说：
Confidence（置信度）：表示使用包含A的事务中同时包含B事务的比例，即同时包含A和B的事务占包含A事务的比例。公式表达：

$$
Confidence=P(A \cap B)/P(A)
$$

还是看上面的例子：
$$
\{黄油, 牛奶\} ⇒ \{面包\}
$$

>此时，同时买了黄油，牛奶的人有4个人，分别是Jack, Mary, Sayani, Tom
买了黄油，牛奶之后又买了面包的人有两个，是Jack和Sayani

所以这里置信度为：$2/4=50\%$


### 面向物品的模型与面向用户的模型
前面所述基千规则的协同过滤均是面向物品的。也可以类似地构建面向用户的模型。
这些模型使用用户之间的相关性而不是物品之间的相关性。在这些情况下关联规则反映的是用户之间的相似性，而非物品之间的相似性。例如：
$$
(用户＝ Alice, 评分＝喜欢) ⇒ (用户＝ Bob, 评分＝不喜欢)
$$

$$
(用户＝ Alice, 评分＝喜欢) AND (用户＝ Peter, 评分＝不喜欢)
⇒(用户＝ John, 评分＝喜欢)
$$

第一条规则说明用户Bob 倾向于不喜欢Alice喜欢的东西。第二条规则说明John 倾向于喜欢Alice喜欢但Peter不喜欢的东西。这些都能通过计算得出概率。


# 基于内容的推荐系统
基于内容的推荐系统尝试为用户匹配那些与其喜欢的物品相似的物品。这种相似性不一定基于用户之间的评分相关性，而是基于用户喜欢的对象的属性。不同于使用与目标用户相关的其他用户评分的协同过滤方法，基于内容的系统更关注目标用户自己的评分，以及用户喜欢的物品的属性。

在基础层面上，基于内容的系统依赖于两个数据来源：
1. 第一个数据来源是根据以内容为中心的属性对各种物品的描述，例如制造商对物品的文本描述。
2. 第二个数据源是用户画像，其根据用户对各种物品的反馈而生成。

## 基于内容的系统的基本组件
基于内容的系统的主要组件包括（离线）预处理部分、（离线）学习部分和在线预测部分。离线部分用于创建汇总模型（一般是分类或回归模型）， 然后将该模型用于在线生成给用户的推荐。基于内容的系统的各个组成部分如下：
1. 预处理和特征提取： 基于内容的系统广泛应用于各种领域． 如网页、产品描述、新闻、音乐功能等。在大多数情况下特征提取自这些不同的数据来源，并被转换成基于关键词的向量空间表示。这是所有基于内容的推荐系统的第一步，它是与领域高度相关的。然而，正确提取最具信息性的特征对于有效运行基于内容的推荐系统来说至关重要。
2. 基于内容的用户画像学习： 如前所述，基于内容的模型与给定的用户密切相关。因此，需要构建特定于用户的模型，进而根据他们过去的购买或评分历史来预测用户对物品的兴趣。为了实现这一目标，需要利用用户反馈， 这可以通过当前已知评分（显式反馈）或用户活动（隐式反馈）的形式表现。这些反馈与物品的属性一起使用以建立训练数据，从而构建学习模型。本阶段通常与分类或回归建模基本相同， 这取决于反馈是分类（例如是否选择物品的二元操作）还是数字（例如评分或购买频率）类型的。因为所得到的模型在概念上将用户兴趣（评分）与物品属性关联起来， 所以该模型被称为用户画像。
3. 过滤和推荐：在此步骤中，使用上一步学习的模型对特定用户给出推荐的物品。

## 预处理和特征提取
### 特征提取
在特征提取阶段， 不同物品的描述会被提取出来。尽管我们可以使用任意一种表示，例如多维数据表示， 但最常见的方法是从底层数据中提取关键词。做出这种选择是因为非结构化文本描述通常在各种领域中广泛使用，并且它们仍然是最自然的描述物品的方式。在许多情况下，可以用多个字段来描述物品的各个方面。例如， 书商可能会提供书籍的文字描述， 以及描述内容、标题和作者的关键词。在一些情况下这些描述会被转换成一系列的关键词。而在其他情况下， 可以直接使用多维（结构化）表示。当属性包含数值（如价格）或从某个较小的域中取出的值（如颜色）时， 后者更为适用。

### 特征清洗
收集的数据中可能会有我们不需要的项目，我们需要对数据进行预处理。例如：
1. 停止词删除：从物品的自由描述中提取的大部分文本将包含许多与物品相关性不强的常用词。这样的词通常是高频词。例如，“a" "an" 和“ the" 这样的词对千正在处理的物品来说没什么作用。在电影推荐应用中， 通常会在剧情介绍中找到这样的词。一般来说， 冠词、介词、连词和代词被视为停止词。在大多数情况下， 各种语言都有停止词的标准化列表。
2. 词干提取： 词干提取过程合并了同一个词的不同变形。例如， 同一单词的单复数或不同时态会被合并。在一些情况下， 会从各种词汇中提取共同的词根。例如，“hoping"和“ hope" 这样的词汇被合并成了共同的词根“hop”。当然， 词干提取有时会产生副作用， 因为类似于“hop" 这样的词可能具有多种不同的含义。
3. 短语提取：这一步工作是检测出文档中频繁同时出现的单词。例如，“hot dog"。这样的短语具有与组成它的单词不同的含义。