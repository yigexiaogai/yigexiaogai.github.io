---
title: 推荐系统（2）
date: 2023-10-31 01:23:04
tags: [推荐系统, 研究生课程]
categories: [研究生课程]
mathjax: true
cover: https://s2.loli.net/2023/10/28/cTiwMuImVXsdL8E.jpg
---

# 基于近邻的协同过滤（Neighborhood-Based Collaborative Filtering）
基于近邻的协同过滤算法， 也被称为基于内存的算法(memory-based algorithm)，是最早的为协同过滤而开发的算法之一。这类算法是基于相似的用户以相似的行为模式对物品进行评分， 并且相似的物品往往获得相似的评分这一事实。基于近邻的算法分为以下两个基本类型：
1. 基于用户的协同过滤：这种类型中，把与目标用户A相似的用户的评分用来为A进行推荐。
2. 基于物品的协同过滤：为了推荐目标物品B, 首先确定一个物品集合S, 使S中的物品与B相似度最高。

基于用户的协同过滤与基于物品的协同过滤的一个重要区别是： **前者利用相似用户的评分来预测该用户的评分；后者利用用户自己对相似物品的评分来预测用户对其他物品的评分。**前者利用用户（评分矩阵的行）之间的相似性来定义近邻；后者利用物品（评分矩阵的列）之间的相似性定义近邻。因此，这两种方法是互补的关系。

现在我们创建一个用户对于物品的评分矩阵，表头为项目编号，左侧第一列为用户编号。
|       | item1 | item2 | item3 | item4 | item5 |
| ---   | ---   | ---   | ---   | ---   | ---   |
| user1 |   1   |       |       |   3   |   6   |
| user2 |       |   5   |       |   3   |   4   |
| user3 |   5   |   2   |  1    |   2   |   2   |

* 在实际情况中，这个表一般会有很多行很多列，非常庞大，而且是稀疏（有很多空数据），接下来我们要做的事情，就是对这个稀疏矩阵做处理。

## 评分矩阵的关键性质
我们假设R代表 m X n 的评分矩阵，其中m表示用户数， n表示物品数， r<sub>uj</sub>表示用户u对物品j的评分。矩阵中只有小部分数据是已知的，我们称已知的数据为训练数据，未知的数据为测试数据。

### 长尾性（long-tail）
物品评分的分布常常满足现实世界中的长尾(long-tail) 属性。这个名字是一个非常形象的表述。在现实情况中，只有一小部分商品会被高频率的评价，或者被点击，也就是所谓的爆款商品，然而，大部分的商品，也许和爆款商品类似，但是只能被大数据埋没在海面之下。当我们把商品和其被关注的频率画成一张表格的时候，“长尾性”就体现出来了。

如图，X轴表示物品的序号，Y轴表示被关注的程度。看来大部分商品都没有被关注呀！
{%asset_img 1.png%}

## 通过基于近邻的方法预测评分
### 基于用户的邻近模型
首先是“基于用户的邻近模型”。我们来总结一下我们要做的事。
* 目标：预测评分矩阵中空的数据部分
* 方法：以一个用户A为基准，寻找和用户A相似的其他用户BCD...，寻找规律预测BCD...对项目的评分

为了方便理解，我们举一个实例。下面我来构建一个表格，表示各个用户对电影的评分，评分为10分制。

定义一个矩阵R：
|      | item1 | item2 | item3 | item4 | item5 | item6 |
| ---  | --- | --- | --- | --- | --- | --- |
| user1  |  7   |  6   |  7   |  4   |  5   |  4   |
| user2  |  6   |  7   |  ?   |  4   |  3   |  4   |
| user3  |  ?   |  3   |  3   |  1   |  1   |  ?   |
| user4  |  1   |  2   |  2   |  3   |  3   |  4   |
| user5  |  1   |  ?   |  1   |  2   |  3   |  3   |

根据我们上述的“方法”，我们需要知道两个用户之间有**多相似**，“相似”这个东西总不是你说说相似就相似吧，所以我们需要一个数学方法，来讲两个用户之间的相似度定量表示出来。以下就是最经典的方法：
>step1: 对于拥有m位用户和n件物品的mXn的评分矩阵 $R = [r_uj]$ , $I_u$表示已经被用户u评价的物品的**序号之集合**。注意，是**序号**。

例如，user1和user2的I：
$$ I_u1 = \{1, 2, 3, 4, 5, 6\}; I_u2 = \{1, 2, 4, 5, 6\}$$

所以，我们可以得到两位用户之间共同评价的物品的列表集合：
$$ I_u1 \cap I_u2 = \{1, 2, 4, 5, 6\}$$

我们需要用一个Pearson相关系数(Pearson correlation coefficient)来衡量用户u和用户v之间评分向量的相似程度$Sim(u, v)$，那么，如何计算Pearson相关系数呢？

>step2:利用每位用户u的评分计算每位用户的平均评分$μ_u$
$$ μ_u= \frac{\Sigma_{k \in I_u} r_{uk}}{|I_u|}
$$

例如，计算user1的$μ_u$：
$$
μ_u=\frac{7+6+7+4+5+4}{6}=5.5
$$

> step3:接下来，user u和v之间的Pearson相关系数定义如下：
$$
Sim(u,v) = Pearson(u,v) =\frac{\Sigma_{k \in{I_u \cap I_v}}(r_{uk}-μ_u)·(r_{vk}-v_μ)}{\sqrt{\Sigma_{k \in{I_u \cap I_v}}(r_{uk}-μ_u)^2} · \sqrt{\Sigma_{k \in{I_u \cap I_v}}(r_{vk}-v_μ)^2}}
$$

例如，我们来计算一下user1和user2的皮尔逊相关系数。
首先，
$$
u_{1_μ} = \frac{7+6+7+4+5+4}{6}=5.5 \\
u_{3_μ} = \frac{3+3+1+1}{4} = 2
$$

然后，
$$
I_1 \cap I_3=\{2, 3, 4, 5\}
$$

$$
Pearson(1,3) = \frac{(6-5.5)*(3-2)+(7-5.5)*(3-2)+(4-5.5)*(1-2)+(5-5.5)*(1-2)}{\sqrt{0.5^2+1.5^2+(-1.5)^2+(-0.5)^2}·\sqrt{1^2+1^2+(-1)^2+(-1)^2}} = 0.894
$$

* 严格来说， 传统意义上的Pearson(u, v) 要求仅对用户u和用户v均做出评分的物品计算均值。也就是说上面的$u_{1_μ}$将会变成$\frac{6+7+4+5}{4}=5.5$， 很难说哪种方法是比较好的方法，但是，我们考虑，如果两个用户的共同评价集合中只有一个共同元素时，Pearson系数就有点没意义了。

>step4:接下来我们还要对用户的评分矩阵**按行进行均值中心化**，均值中心化就是把原先的矩阵都减去均值。例如：

|      | item1 | item2 | item3 | item4 | item5 | item6 |均值|
| ---  | --- | --- | --- | --- | --- | --- |----
| user1  |  7   |  6   |  7   |  4   |  5   |  4   |5.5
| user2  |  6   |  7   |  ?   |  4   |  3   |  4   |4.8
| user3  |  ?   |  3   |  3   |  1   |  1   |  ?   |2
| user4  |  1   |  2   |  2   |  3   |  3   |  4   |2.5
| user5  |  1   |  ?   |  1   |  2   |  3   |  3   |2

$$
\rightarrow
$$

|      | item1 | item2 | item3 | item4 | item5 | item6 |
| ---  | --- | --- | --- | --- | --- | --- |
| user1  |  1.5   |  0.5   |  1.5   |  -1.5   |  -0.5   |  -1.5   |
| user2  |  1.2   |  2.2   |  ?   |  -0.8   |  -1.8   |  -0.8   |
| user3  |  ?   |  1   |  1   |  -1   |  -1   |  ?   |
| user4  |  -1.5   |  -0.5   |  -0.5   |  0.5   |  0.5   |  1.5   |
| user5  |  -1   |  ?   |  -1   |  0   |  1   |  1   |

* **为什么要这么做呢？其实找相似度的感觉，可以理解成两个函数长得像不像，如果两条曲线重合，那么他们就一样，就是完全相似，但是如果有一条线上下平移一下呢？他们形状还是一样，但是相当于说，一个人整体给高分（是个好人），一个人整体给低分（是个坏人），这时候如果不均值化，当我们把好人的权重给坏人的时候，显然，坏人就打高分了，所以，这就是均值化的原因**

用户u对物品j按均值中心化后的评分．$s_{uj}$被定义为原始评分减去其平均评分。
$$
s_{uj} = r_{uj} - μ_u \forall u \in\{1...m\}
$$

>step5:令$P_u(j)$表示与目标用户u最相近的K位对物品做出评分的用户集合，**一般相关为负数的都不会纳入其中**。终于，整体的基于近邻的预测函数$\hat{r}_{uj}$诞生了！

$$
\hat{r}_{uj}= μ_u + \frac{\Sigma_{v \in P_u(j)} Sim(u,v) · s_{vj}}{\Sigma_{v \in P_u(j)}|Sim(u,v)|}
$$

